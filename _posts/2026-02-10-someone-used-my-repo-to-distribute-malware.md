---
layout: post
title: "i build AI governance tools. someone used my repo to distribute malware."
description: "a real supply chain attack on an open-source AI security project, and what it says about trust"
permalink: /writing/someone-used-my-repo-to-distribute-malware
redirect_from:
  - /2026/02/10/someone-used-my-repo-to-distribute-malware.html
---

i build tools that help companies securely connect AI to their systems. today i discovered that someone forked my repo and turned it into a malware distribution page.

### what i found

this morning i noticed a fork of [gatewaystack-chatgpt-starter](https://github.com/davidcrowe/gatewaystack-chatgpt-starter) with changes to the README. i clicked through expecting a minor edit.

the entire README had been rewritten.

<img src="/assets/supply-chain-attack/fake-readme.png" alt="The attacker's version of my repo — note the Download Now badge and installer instructions on what is actually a Node.js server project" style="width:50%">

my README documents a TypeScript server you run with `npm`. the new one reads like a software product landing page. "Download the Installer." "Double-click the .exe to run." A big blue "Download Now" badge. system requirements listing "Windows 10 or later" and "minimum 4 GB of RAM."

*this is a Node.js project. there is no installer. there is no .exe.*

the "Download Now" button and every "Releases page" link point to the same place: a 1.33 MB zip file buried in `src/gateway/`.

![The zip file committed directly into the source tree](/assets/supply-chain-attack/zip-in-src.png)

not in GitHub Releases. not in a package manager. committed directly into the source tree where GitHub won't preview it and most people won't inspect it.

### the red flags

the README reads like something AI would generate. it's obvious once you know what you're looking at — generic product copy bolted onto a project it doesn't describe. the attacker didn't understand (or care) what the project actually does. they just needed a convincing download page.

![Three commits: a complete README rewrite, the zip file, then updated links pointing to the zip](/assets/supply-chain-attack/commit-history.png)

the commit history tells the story in three steps. first, replace the README with fake installer copy. second, commit the zip file. third, update all links to point directly at the zip. clean. methodical.

they copied my repo description and topics verbatim — `oauth`, `jwt`, `mcp`, `chatgpt`, `enterprise-ai`, `model-context-protocol`. they even set up a GitHub Pages site (kaushalpatil02019.github.io) mirroring my project description. this is SEO hijacking — coordinated across the repo, its metadata, and a companion site. anyone searching GitHub for these terms could land on the fork instead of the original.

and my name shows up as a contributor.

<img src="/assets/supply-chain-attack/contributors.png" alt="My name listed as a contributor on the attacker's fork" style="width:50%">

because they forked my repo, my commits carry over. the page shows me right there in the sidebar — lending false legitimacy to a project designed to trick people into downloading malware.

the attacker's own profile? no bio, no avatar, 499 contributions crammed into January–February 2026 — all in this one repo.

![The attacker's profile: no identity, padded contribution graph](/assets/supply-chain-attack/attacker-profile.png)

that's not a developer contributing to open source. that's someone manufacturing the appearance of activity.

### why this repo?

this wasn't random.

AI governance and security repos attract a specific audience: developers integrating AI into enterprise systems, security-conscious engineers, people evaluating AI infrastructure. *people with elevated system access and a reason to download tools.*

the keyword farming confirms it. `oauth`, `jwt`, `enterprise-ai`, `model-context-protocol` — these are the exact terms enterprise teams search when building production AI systems. my SEO positioning is working, which means it's also a target.

if you're building something that ranks for high-value enterprise keywords, your repo is an attack surface. not just for code vulnerabilities — for social engineering through GitHub's fork and discovery model.

### the trust problem

this is a live example of something broken in how we trust open-source code.

GitHub's fork model makes impersonation trivial. click "fork," rewrite the README, add a payload, and you have a page that looks nearly identical to the original — complete with the original author's name, description, and topics. the platform that enables open collaboration also enables effortless impersonation.

the trust gap in LLM systems is user ↔ AI ↔ backend. in software supply chains, it's developer ↔ platform ↔ code. same structure, same failure mode.

we trust code provenance based on proximity to the original repo — not verified identity. a fork *looks like the real thing* because GitHub's model doesn't distinguish between legitimate collaboration and impersonation. that's a feature for open source. it's a vulnerability for supply chains.

### what i did

i reported the repo to GitHub. the ticket is open.

![GitHub Support confirmation](/assets/supply-chain-attack/github-support.png)

but this raises a question i keep coming back to: ***what's the trust model for open-source tooling in the AI era?***

when the tools being targeted are designed for AI governance — tools that control how AI agents access sensitive systems — the stakes compound. you're not just distributing malware. you're potentially compromising the security layer itself.

this is part of why a hosted version of these tools — where identity is verified, provenance is clear, and you're not cloning a repo from a stranger — has structural advantages. not because open source is bad. because the trust model has gaps that attackers are actively exploiting.

if you maintain an open-source project with enterprise keywords: check your forks. if you're downloading AI tools from GitHub: verify the source. check the commit history. check the contributor profiles. don't trust the README.
