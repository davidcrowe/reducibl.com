Okay, here's a draft of the blog post based on the provided information:

```
---
layout: post
title: "build log: jan 31"
description: "i'm building an art education app inside chatgpt, and trying not to get pwned in the process."
---

### what i shipped today
i'm trying to build a structured art curriculum on top of a messy dataset. i added a 4-phase plan for learning features in the apprentice app, inspired by betty edwards' "drawing on the right side of the brain". also, i drafted a linkedin post about the security risks of using claude code. ![linkedin post draft](/assets/screenshots/2026-01-31/screenshot-1.png)

### the wikiart curated set has serious holes
the existing wikiart curated set had serious holes. i'm talking key artists and genres missing. so, i curated a list of ~200 canonical artworks from wikimedia commons to fill the gaps. i fetched the data from the wikimedia commons api to automate it, because i'm lazy. it's wild how much manual work still goes into these "ai" projects.

### local inference may not be the answer
i was planning to transition to a new mac mini with 48gb of memory for local inference and development. the idea was to have it running in the background, enriching the dataset, and freeing up my main machine. but i'm starting to think local inference may not be the most cost-effective solution for large-scale enrichment jobs. might be cheaper to just pay for cloud compute.

---
david crowe â€” [reducibl.com](https://reducibl.com)
```